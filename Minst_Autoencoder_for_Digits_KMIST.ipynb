{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e879bc21",
   "metadata": {},
   "source": [
    "__Imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4cee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e4f778",
   "metadata": {},
   "source": [
    "### Load in the data__\n",
    "* Splits the data\n",
    "* Shuffle the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b27b45",
   "metadata": {},
   "source": [
    "__Batch_size=-1 to get the full dataset in NumPy arrays from the returned tf.Tensor object__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902347e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Michael\\tensorflow_datasets\\emnist\\byclass\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d0dbe0e62047c88ee1567f2fd49ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e6c8abcab8407cbd78d3a678be60cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a192ff4a691245b9b68fe5699aad05d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b4eef111054cb48b06675b2d70b988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c5e25de4de4e4e9d3235b6f8c597b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2452b3b5814404a76e4067af7ee909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_test,mnist_val,mnist_train = tfds.load(name=\"kmnist\",\n",
    "                                             split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n",
    "                                             batch_size=-1,\n",
    "                                             shuffle_files=True\n",
    "                                            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc459d6",
   "metadata": {},
   "source": [
    "__tfds.as_numpy return a generator that yields NumPy array records out of a tf.data.Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ba191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfds.as_numpy return a generator that yields NumPy array records out of a tf.data.Dataset\n",
    "mnist_train = tfds.as_numpy(mnist_train) \n",
    "mnist_val = tfds.as_numpy(mnist_val) \n",
    "mnist_test = tfds.as_numpy(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6d7ef",
   "metadata": {},
   "source": [
    "__Seperate the x and y__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb69856",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = mnist_train[\"image\"], mnist_train[\"label\"]\n",
    "x_valid,y_valid = mnist_val[\"image\"], mnist_val[\"label\"]\n",
    "x_test, y_test = mnist_test[\"image\"], mnist_test[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5326c5",
   "metadata": {},
   "source": [
    "__Check lengths__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e04694",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set size: \", len(x_train))\n",
    "print(\"Valid set size: \", len(x_valid))\n",
    "print(\"Test set size: \", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934502df",
   "metadata": {},
   "source": [
    "__Data Normalization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values\n",
    "x_train = x_train/255\n",
    "x_valid = x_valid/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d48a0c2",
   "metadata": {},
   "source": [
    "__Visualize the Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(6, 6))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(x_train[i], cmap=plt.cm.binary, interpolation='nearest')\n",
    "    # label the image with the target value\n",
    "    ax.text(0, 7, str(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052397f9",
   "metadata": {},
   "source": [
    "### Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7b7f5f",
   "metadata": {},
   "source": [
    "__Accuracy Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d514f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f0040",
   "metadata": {},
   "source": [
    "__Always a good habit to randomized seeds__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c0369",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412500cb",
   "metadata": {},
   "source": [
    "__Autoencoder Model__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40eb42e",
   "metadata": {},
   "source": [
    "__Encoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aff753",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_encoder = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(28,28,1)),\n",
    "    keras.layers.Conv2D( filters=16, kernel_size=3, \n",
    "                        padding=\"SAME\",\n",
    "                        activation=\"selu\" ),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D( filters=32, kernel_size=3, \n",
    "                        padding=\"SAME\",\n",
    "                        activation=\"selu\" ),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D( filters=64, kernel_size=3, \n",
    "                        padding=\"SAME\",\n",
    "                        activation=\"selu\" ),\n",
    "    keras.layers.MaxPool2D(pool_size=2)\n",
    "])\n",
    "stacked_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9bf857",
   "metadata": {},
   "source": [
    "__Decoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_decoder = keras.models.Sequential([\n",
    "    # padding=\"VALID\" since 3*2 !=7\n",
    "    keras.layers.Conv2DTranspose( 32, kernel_size=3, \n",
    "                                 strides=2, padding=\"VALID\",\n",
    "                                 activation=\"selu\", input_shape=[3,3,64]), #==> (None, 7, 7, 32)\n",
    "    # 7x2 (strides)=14 and padding=0\n",
    "    keras.layers.Conv2DTranspose( 16, kernel_size=3, strides=2, padding=\"SAME\",\n",
    "                                 activation=\"selu\" ), #==> (None, 14, 14, 16)\n",
    "    # 14x2(strides)=28\n",
    "    keras.layers.Conv2DTranspose( 1, kernel_size=3, strides=2, padding=\"SAME\", \n",
    "                                 activation=\"sigmoid\" ), #==> (None, 28, 28, 1)\n",
    "    keras.layers.Reshape([28,28])\n",
    "])\n",
    "stacked_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1befbd",
   "metadata": {},
   "source": [
    "__Now connect them together__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b07b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a92e09",
   "metadata": {},
   "source": [
    "__Binary cross-entropy loss: each pixel(or each label) intensity represents the probability that the pixel should so model converges faster__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460cd5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
    "                   optimizer=tf.keras.optimizers.SGD(learning_rate=1.5), \n",
    "                   metrics=[rounded_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0154009",
   "metadata": {},
   "source": [
    "__Using x_train as both the inputs and the targets and similarly, we use x_valid as both the validation inputs and targets__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cced9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = stacked_ae.fit(x_train, x_train,\n",
    "                         epochs=20,\n",
    "                         validation_data=(x_valid, x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa0380",
   "metadata": {},
   "source": [
    "### Reconstruction Zone & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b51fa0",
   "metadata": {},
   "source": [
    "__Function to show plots__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb433622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2963cad8",
   "metadata": {},
   "source": [
    "__Function to Reconstruction Images given a model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reconstructions(model, images=x_valid, n_images=5):\n",
    "    reconstructions = model.predict(images[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf090e70",
   "metadata": {},
   "source": [
    "__Top is Original & Bottom is Reconstructed__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23538a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_reconstructions(stacked_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da239c3",
   "metadata": {},
   "source": [
    "__Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2301258",
   "metadata": {},
   "source": [
    "__t-SNE is based on probability distributions with random walk on neighborhood graphs to find the structure\n",
    "within the data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "from sklearn.manifold import TSNE\n",
    "X_valid_compressed = stacked_ae.predict(x_valid)\n",
    "nsamples, nx, ny,oth = X_valid_compressed.shape\n",
    "X_valid_compressed = X_valid_compressed.reshape((nsamples,nx*ny))\n",
    "tsne = TSNE()\n",
    "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
    "X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c0645",
   "metadata": {},
   "source": [
    "__t-SNE Plot__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e659833",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e63f62",
   "metadata": {},
   "source": [
    "__t-SNE with Images__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90054bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "plt.figure(figsize=(10, 8))\n",
    "cmap = plt.cm.tab10\n",
    "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=cmap)\n",
    "image_positions = np.array([[1., 1.]])\n",
    "for index, position in enumerate(X_valid_2D):\n",
    "    dist = np.sum((position - image_positions) ** 2, axis=1)\n",
    "    if np.min(dist) > 0.02: # if far enough from other images\n",
    "            image_positions = np.r_[image_positions, [position]]\n",
    "            imagebox = mpl.offsetbox.AnnotationBbox(\n",
    "                mpl.offsetbox.OffsetImage(x_valid[index], cmap=\"binary\"),\n",
    "                position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n",
    "    plt.gca().add_artist(imagebox)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_ACC",
   "language": "python",
   "name": "gpu_acc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
